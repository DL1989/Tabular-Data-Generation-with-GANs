{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eb0edd2",
   "metadata": {},
   "source": [
    "### Code by Denis Loechel as part of master thesis on synthetic data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d277b7",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee8e2fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n",
    "from datetime import datetime\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02eb28ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45dbdb6",
   "metadata": {},
   "source": [
    "# Importing dataset and evaluating the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044f9a7e",
   "metadata": {},
   "source": [
    "### Model Explanation\n",
    "\n",
    "#### In this model selection below , given our HR dataset and the part of the dataset , we aim to classify whether or not a future employee will be terminated  based on the other variables on the dataset such as salary, termination, special projects etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d9bca2",
   "metadata": {},
   "source": [
    "# 1. Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5209ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading our HR CSV file\n",
    "data = pd.read_csv(\"20230308_Updated_HR_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c5b0f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EmpID', 'MarriedID', 'GenderID', 'DeptID', 'Salary', 'Termd',\n",
       "       'PositionID', 'CitizenDesc', 'ManagerID', 'EmpSatisfaction',\n",
       "       'SpecialProjectsCount', 'DaysLateLast30', 'Absences', 'BirthYear',\n",
       "       'YearofTermination', 'YearofHire', 'YearofPerformanceReview',\n",
       "       'YearsinCompany'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87ede95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Termd'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the termd column \n",
    "col_name = data.iloc[:, 5].name\n",
    "col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dcea65",
   "metadata": {},
   "source": [
    "## Model: Train_test_split and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8391dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target label creation for dataset \n",
    "X = data.drop(col_name, axis=1)  # features\n",
    "y = data[col_name]  # target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5b56d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b69a3c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33d1035",
   "metadata": {},
   "source": [
    "## Combined Classification Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "85485c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: Accuracy: 100.00%, F1-Score: 1.000, Weighted F1-Score: 1.000\n",
      "DT: Accuracy: 99.60%, F1-Score: 0.996, Weighted F1-Score: 0.996\n",
      "RF: Accuracy: 100.00%, F1-Score: 1.000, Weighted F1-Score: 1.000\n",
      "SVM: Accuracy: 66.93%, F1-Score: 0.669, Weighted F1-Score: 0.539\n"
     ]
    }
   ],
   "source": [
    "# Classifiers\n",
    "model_dict = {\n",
    "    \"LR\": LogisticRegression(),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "# Evaluate each model using KFold cross-validation\n",
    "results = []\n",
    "names = []\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_score': 'f1_micro',\n",
    "    'weighted_f1': 'f1_weighted'\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in model_dict.items():\n",
    "    pipeline = make_pipeline(model)\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    accuracy = cv_results[\"test_accuracy\"].mean()\n",
    "    f1_score = cv_results[\"test_f1_score\"].mean()\n",
    "    f1_weighted = cv_results[\"test_weighted_f1\"].mean()\n",
    "\n",
    "    results.append([accuracy, f1_score, f1_weighted])\n",
    "    names.append(name)\n",
    "    print(f\"{name}: Accuracy: {accuracy:.2%}, F1-Score: {f1_score:.3f}, Weighted F1-Score: {f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886a0000",
   "metadata": {},
   "source": [
    "# 2. CTGAN Dataset (500 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cfe0b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading our HR CSV file\n",
    "data = pd.read_csv(\"synthetic_dataset_CTGAN_epochs500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "010550e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Termd'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the termd column \n",
    "col_name = data.iloc[:, 5].name\n",
    "col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdb58fe",
   "metadata": {},
   "source": [
    "## Model: Train_test_split and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a9530a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target label creation for dataset \n",
    "X = data.drop(col_name, axis=1)  # features\n",
    "y = data[col_name]  # target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "014201a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dd6e72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7878b9fd",
   "metadata": {},
   "source": [
    "## Combined Classification Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a7acbcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: Accuracy: 91.33%, F1-Score: 0.913, Weighted F1-Score: 0.872\n",
      "DT: Accuracy: 82.04%, F1-Score: 0.820, Weighted F1-Score: 0.831\n",
      "RF: Accuracy: 91.33%, F1-Score: 0.913, Weighted F1-Score: 0.872\n",
      "SVM: Accuracy: 91.33%, F1-Score: 0.913, Weighted F1-Score: 0.872\n"
     ]
    }
   ],
   "source": [
    "# Classifiers\n",
    "model_dict = {\n",
    "    \"LR\": LogisticRegression(),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "# Evaluate each model using KFold cross-validation\n",
    "results = []\n",
    "names = []\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_score': 'f1_micro',\n",
    "    'weighted_f1': 'f1_weighted'\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in model_dict.items():\n",
    "    pipeline = make_pipeline(model)\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    accuracy = cv_results[\"test_accuracy\"].mean()\n",
    "    f1_score = cv_results[\"test_f1_score\"].mean()\n",
    "    f1_weighted = cv_results[\"test_weighted_f1\"].mean()\n",
    "\n",
    "    results.append([accuracy, f1_score, f1_weighted])\n",
    "    names.append(name)\n",
    "    print(f\"{name}: Accuracy: {accuracy:.2%}, F1-Score: {f1_score:.3f}, Weighted F1-Score: {f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fc9832",
   "metadata": {},
   "source": [
    "# 3. CTGAN Dataset (1000 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f460125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading our HR CSV file\n",
    "data = pd.read_csv(\"synthetic_dataset_CTGAN_epochs1000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "37d94cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Termd'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the termd column \n",
    "col_name = data.iloc[:, 5].name\n",
    "col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa69f94e",
   "metadata": {},
   "source": [
    "## Model: Train_test_split and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "601cf966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target label creation for dataset \n",
    "X = data.drop(col_name, axis=1)  # features\n",
    "y = data[col_name]  # target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e079e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9c75b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1439259",
   "metadata": {},
   "source": [
    "## Combined Classification Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "06d9b25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: Accuracy: 66.43%, F1-Score: 0.664, Weighted F1-Score: 0.530\n",
      "DT: Accuracy: 55.55%, F1-Score: 0.556, Weighted F1-Score: 0.558\n",
      "RF: Accuracy: 65.64%, F1-Score: 0.656, Weighted F1-Score: 0.542\n",
      "SVM: Accuracy: 66.38%, F1-Score: 0.664, Weighted F1-Score: 0.530\n"
     ]
    }
   ],
   "source": [
    "# Classifiers\n",
    "model_dict = {\n",
    "    \"LR\": LogisticRegression(),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "# Evaluate each model using KFold cross-validation\n",
    "results = []\n",
    "names = []\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_score': 'f1_micro',\n",
    "    'weighted_f1': 'f1_weighted'\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in model_dict.items():\n",
    "    pipeline = make_pipeline(model)\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    accuracy = cv_results[\"test_accuracy\"].mean()\n",
    "    f1_score = cv_results[\"test_f1_score\"].mean()\n",
    "    f1_weighted = cv_results[\"test_weighted_f1\"].mean()\n",
    "\n",
    "    results.append([accuracy, f1_score, f1_weighted])\n",
    "    names.append(name)\n",
    "    print(f\"{name}: Accuracy: {accuracy:.2%}, F1-Score: {f1_score:.3f}, Weighted F1-Score: {f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0045af1",
   "metadata": {},
   "source": [
    "# 4. CTGAN Dataset (1500 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6d65e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading our HR CSV file\n",
    "data = pd.read_csv(\"synthetic_dataset_CTGAN_epochs1500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dbe8fab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Termd'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the termd column \n",
    "col_name = data.iloc[:, 5].name\n",
    "col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966cc565",
   "metadata": {},
   "source": [
    "## Model: Train_test_split and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "63bc8338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target label creation for dataset \n",
    "X = data.drop(col_name, axis=1)  # features\n",
    "y = data[col_name]  # target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6a58e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9dac4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d70a3f",
   "metadata": {},
   "source": [
    "## Combined Classification Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e5a99b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: Accuracy: 85.50%, F1-Score: 0.855, Weighted F1-Score: 0.788\n",
      "DT: Accuracy: 73.02%, F1-Score: 0.730, Weighted F1-Score: 0.741\n",
      "RF: Accuracy: 85.50%, F1-Score: 0.855, Weighted F1-Score: 0.788\n",
      "SVM: Accuracy: 85.50%, F1-Score: 0.855, Weighted F1-Score: 0.788\n"
     ]
    }
   ],
   "source": [
    "# Classifiers\n",
    "model_dict = {\n",
    "    \"LR\": LogisticRegression(),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "# Evaluate each model using KFold cross-validation\n",
    "results = []\n",
    "names = []\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_score': 'f1_micro',\n",
    "    'weighted_f1': 'f1_weighted'\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in model_dict.items():\n",
    "    pipeline = make_pipeline(model)\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    accuracy = cv_results[\"test_accuracy\"].mean()\n",
    "    f1_score = cv_results[\"test_f1_score\"].mean()\n",
    "    f1_weighted = cv_results[\"test_weighted_f1\"].mean()\n",
    "\n",
    "    results.append([accuracy, f1_score, f1_weighted])\n",
    "    names.append(name)\n",
    "    print(f\"{name}: Accuracy: {accuracy:.2%}, F1-Score: {f1_score:.3f}, Weighted F1-Score: {f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ec2f0",
   "metadata": {},
   "source": [
    "# 5. CTGAN Dataset (2000 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "924e11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading our HR CSV file\n",
    "data = pd.read_csv(\"synthetic_dataset_CTGAN_epochs2000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "18fb0b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Termd'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the termd column \n",
    "col_name = data.iloc[:, 5].name\n",
    "col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad8840",
   "metadata": {},
   "source": [
    "## Model: Train_test_split and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "67e474f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target label creation for dataset \n",
    "X = data.drop(col_name, axis=1)  # features\n",
    "y = data[col_name]  # target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4aa7bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "904f445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e12a8f4",
   "metadata": {},
   "source": [
    "## Combined Classification Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "83d082e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: Accuracy: 75.37%, F1-Score: 0.754, Weighted F1-Score: 0.648\n",
      "DT: Accuracy: 61.57%, F1-Score: 0.616, Weighted F1-Score: 0.621\n",
      "RF: Accuracy: 75.32%, F1-Score: 0.753, Weighted F1-Score: 0.649\n",
      "SVM: Accuracy: 75.37%, F1-Score: 0.754, Weighted F1-Score: 0.648\n"
     ]
    }
   ],
   "source": [
    "# Classifiers\n",
    "model_dict = {\n",
    "    \"LR\": LogisticRegression(),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "# Evaluate each model using KFold cross-validation\n",
    "results = []\n",
    "names = []\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_score': 'f1_micro',\n",
    "    'weighted_f1': 'f1_weighted'\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in model_dict.items():\n",
    "    pipeline = make_pipeline(model)\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    accuracy = cv_results[\"test_accuracy\"].mean()\n",
    "    f1_score = cv_results[\"test_f1_score\"].mean()\n",
    "    f1_weighted = cv_results[\"test_weighted_f1\"].mean()\n",
    "\n",
    "    results.append([accuracy, f1_score, f1_weighted])\n",
    "    names.append(name)\n",
    "    print(f\"{name}: Accuracy: {accuracy:.2%}, F1-Score: {f1_score:.3f}, Weighted F1-Score: {f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e327b72d",
   "metadata": {},
   "source": [
    "# 6. CopulaGAN (500 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9ad7b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading our HR CSV file\n",
    "data = pd.read_csv(\"synthetic_dataset_CopulaGANepochs500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cb55828f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Termd'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the termd column \n",
    "col_name = data.iloc[:, 5].name\n",
    "col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0af77d",
   "metadata": {},
   "source": [
    "## Model: Train_test_split and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2ad23aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target label creation for dataset \n",
    "X = data.drop(col_name, axis=1)  # features\n",
    "y = data[col_name]  # target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "27c00198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0c27d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0f323",
   "metadata": {},
   "source": [
    "## Combined Classification Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3942d489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: Accuracy: 82.58%, F1-Score: 0.826, Weighted F1-Score: 0.747\n",
      "DT: Accuracy: 69.38%, F1-Score: 0.694, Weighted F1-Score: 0.704\n",
      "RF: Accuracy: 82.58%, F1-Score: 0.826, Weighted F1-Score: 0.747\n",
      "SVM: Accuracy: 82.58%, F1-Score: 0.826, Weighted F1-Score: 0.747\n"
     ]
    }
   ],
   "source": [
    "# Classifiers\n",
    "model_dict = {\n",
    "    \"LR\": LogisticRegression(),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "# Evaluate each model using KFold cross-validation\n",
    "results = []\n",
    "names = []\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_score': 'f1_micro',\n",
    "    'weighted_f1': 'f1_weighted'\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in model_dict.items():\n",
    "    pipeline = make_pipeline(model)\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    accuracy = cv_results[\"test_accuracy\"].mean()\n",
    "    f1_score = cv_results[\"test_f1_score\"].mean()\n",
    "    f1_weighted = cv_results[\"test_weighted_f1\"].mean()\n",
    "\n",
    "    results.append([accuracy, f1_score, f1_weighted])\n",
    "    names.append(name)\n",
    "    print(f\"{name}: Accuracy: {accuracy:.2%}, F1-Score: {f1_score:.3f}, Weighted F1-Score: {f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4537cc98",
   "metadata": {},
   "source": [
    "# 7. CopulaGAN (1000 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1128264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading our HR CSV file\n",
    "data = pd.read_csv(\"synthetic_dataset_CopulaGANepochs1000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc0832dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Termd'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the termd column \n",
    "col_name = data.iloc[:, 5].name\n",
    "col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4009d41c",
   "metadata": {},
   "source": [
    "## Model: Train_test_split and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "448ba905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target label creation for dataset \n",
    "X = data.drop(col_name, axis=1)  # features\n",
    "y = data[col_name]  # target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04abfcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cff493f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3ec79",
   "metadata": {},
   "source": [
    "## Combined Classification Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d76c006b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: Accuracy: 51.23%, F1-Score: 0.512, Weighted F1-Score: 0.352\n",
      "DT: Accuracy: 49.94%, F1-Score: 0.499, Weighted F1-Score: 0.500\n",
      "RF: Accuracy: 49.71%, F1-Score: 0.497, Weighted F1-Score: 0.496\n",
      "SVM: Accuracy: 51.17%, F1-Score: 0.512, Weighted F1-Score: 0.349\n"
     ]
    }
   ],
   "source": [
    "# Classifiers\n",
    "model_dict = {\n",
    "    \"LR\": LogisticRegression(),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "# Evaluate each model using KFold cross-validation\n",
    "results = []\n",
    "names = []\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_score': 'f1_micro',\n",
    "    'weighted_f1': 'f1_weighted'\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in model_dict.items():\n",
    "    pipeline = make_pipeline(model)\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    accuracy = cv_results[\"test_accuracy\"].mean()\n",
    "    f1_score = cv_results[\"test_f1_score\"].mean()\n",
    "    f1_weighted = cv_results[\"test_weighted_f1\"].mean()\n",
    "\n",
    "    results.append([accuracy, f1_score, f1_weighted])\n",
    "    names.append(name)\n",
    "    print(f\"{name}: Accuracy: {accuracy:.2%}, F1-Score: {f1_score:.3f}, Weighted F1-Score: {f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b36c1",
   "metadata": {},
   "source": [
    "# 8. CopulaGAN (1500 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3d6cb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading our HR CSV file\n",
    "data = pd.read_csv(\"synthetic_dataset_CopulaGANepochs1500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "713dd90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Termd'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the termd column \n",
    "col_name = data.iloc[:, 5].name\n",
    "col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c16b663",
   "metadata": {},
   "source": [
    "## Model: Train_test_split and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "073bca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target label creation for dataset \n",
    "X = data.drop(col_name, axis=1)  # features\n",
    "y = data[col_name]  # target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9a24b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "da9675f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679d0e2e",
   "metadata": {},
   "source": [
    "## Combined Classification Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6a76f022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: Accuracy: 83.01%, F1-Score: 0.830, Weighted F1-Score: 0.753\n",
      "DT: Accuracy: 70.12%, F1-Score: 0.701, Weighted F1-Score: 0.710\n",
      "RF: Accuracy: 83.01%, F1-Score: 0.830, Weighted F1-Score: 0.753\n",
      "SVM: Accuracy: 83.01%, F1-Score: 0.830, Weighted F1-Score: 0.753\n"
     ]
    }
   ],
   "source": [
    "# Classifiers\n",
    "model_dict = {\n",
    "    \"LR\": LogisticRegression(),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "# Evaluate each model using KFold cross-validation\n",
    "results = []\n",
    "names = []\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_score': 'f1_micro',\n",
    "    'weighted_f1': 'f1_weighted'\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in model_dict.items():\n",
    "    pipeline = make_pipeline(model)\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    accuracy = cv_results[\"test_accuracy\"].mean()\n",
    "    f1_score = cv_results[\"test_f1_score\"].mean()\n",
    "    f1_weighted = cv_results[\"test_weighted_f1\"].mean()\n",
    "\n",
    "    results.append([accuracy, f1_score, f1_weighted])\n",
    "    names.append(name)\n",
    "    print(f\"{name}: Accuracy: {accuracy:.2%}, F1-Score: {f1_score:.3f}, Weighted F1-Score: {f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40fe261",
   "metadata": {},
   "source": [
    "# 9. CopulaGAN (2000 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da3a3e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading our HR CSV file\n",
    "data = pd.read_csv(\"synthetic_dataset_CopulaGANepochs2000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ddd0a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Termd'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the termd column \n",
    "col_name = data.iloc[:, 5].name\n",
    "col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d79f54",
   "metadata": {},
   "source": [
    "## Model: Train_test_split and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81d01f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target label creation for dataset \n",
    "X = data.drop(col_name, axis=1)  # features\n",
    "y = data[col_name]  # target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98e39f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0b7b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50321d3",
   "metadata": {},
   "source": [
    "## Combined Classification Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c34316c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: Accuracy: 70.39%, F1-Score: 0.704, Weighted F1-Score: 0.582\n",
      "DT: Accuracy: 56.51%, F1-Score: 0.565, Weighted F1-Score: 0.569\n",
      "RF: Accuracy: 70.21%, F1-Score: 0.702, Weighted F1-Score: 0.583\n",
      "SVM: Accuracy: 70.39%, F1-Score: 0.704, Weighted F1-Score: 0.582\n"
     ]
    }
   ],
   "source": [
    "# Classifiers\n",
    "model_dict = {\n",
    "    \"LR\": LogisticRegression(),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "# Evaluate each model using KFold cross-validation\n",
    "results = []\n",
    "names = []\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_score': 'f1_micro',\n",
    "    'weighted_f1': 'f1_weighted'\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in model_dict.items():\n",
    "    pipeline = make_pipeline(model)\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    accuracy = cv_results[\"test_accuracy\"].mean()\n",
    "    f1_score = cv_results[\"test_f1_score\"].mean()\n",
    "    f1_weighted = cv_results[\"test_weighted_f1\"].mean()\n",
    "\n",
    "    results.append([accuracy, f1_score, f1_weighted])\n",
    "    names.append(name)\n",
    "    print(f\"{name}: Accuracy: {accuracy:.2%}, F1-Score: {f1_score:.3f}, Weighted F1-Score: {f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57440e07",
   "metadata": {},
   "source": [
    "# Documentation Sources for Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20801408",
   "metadata": {},
   "source": [
    "Classification models: https://scikit-learn.org/stable/supervised_learning.html\n",
    "F-1 Score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "KFold cross validation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "Pipeline: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
